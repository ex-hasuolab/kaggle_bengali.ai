{"cells":[{"metadata":{},"cell_type":"raw","source":"- utils\n    |- loader.py ： dataをゲットする方法を記述する（DataAugumentもここ）\n    |- modules.py : model構造を記述 (EfficientNetクラスを使う)\n- solver.py : model.fit又はmodel.fit_generatorはここ．callbackの定義もここ\n- run.py ： parserで入力を受け付けてsolver.pyを実行する．"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -U efficientnet==0.0.4\n# Efficient Netを実行するには以下のtensorflowとkerasが必要．\n# しかしcudaやcuDNNのバージョンがあってないのでkaggleのnotebookでは難しい．\n\n#!pip install --upgrade tensorflow-gpu==1.12.0\n#!pip install --upgrade keras==2.2.4","execution_count":4,"outputs":[{"output_type":"stream","text":"Collecting efficientnet==0.0.4\n  Downloading https://files.pythonhosted.org/packages/a6/80/f2c098284f7c07491e66af18d9a5fea595d4b507d10c0845275b8d47dc6f/efficientnet-0.0.4.tar.gz\nBuilding wheels for collected packages: efficientnet\n  Building wheel for efficientnet (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet: filename=efficientnet-0.0.4-cp36-none-any.whl size=14288 sha256=a9ce648896679f84607f20be72076d1832a481e56a5877e53186006712e11b85\n  Stored in directory: /root/.cache/pip/wheels/5c/34/68/a611a699a28239e964ccf144c0e767cdb5439fee82ec5de6e0\nSuccessfully built efficientnet\nInstalling collected packages: efficientnet\nSuccessfully installed efficientnet-0.0.4\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dataloder ： utils/loder.pyに記述するべき内容\nimport numpy as np\nfrom math import ceil\nfrom scipy import ndimage\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras import utils\nimport keras\n#from tensorflow.keras.datasets.cifar10 import load_data\nfrom tensorflow.keras.datasets.mnist import load_data\n\nclass Dataloder(object):\n    def __init__(self):\n        pass\n    \n    def get_data(self, channel):\n        # load MNIST data\n        (x_train, y_train), (x_test, y_test) = load_data()\n        x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.175)\n\n        self.x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')/255\n        self.x_valid = x_valid.reshape(x_valid.shape[0], 28, 28, 1).astype('float32')/255\n        self.x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')/255\n\n        if channel == 3:\n            self.x_train = np.tile(x_train, 3)\n            self.x_valid = np.tile(x_valid, 3)\n            self.x_test = np.tile(x_test, 3)\n\n        # convert one-hot vector\n        self.y_train = keras.utils.to_categorical(y_train, 10)\n        self.y_valid = keras.utils.to_categorical(y_valid, 10)\n        self.y_test = keras.utils.to_categorical(y_test, 10)\n    \n        pass","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# モジュールの構造：uitils.modules.pyに記述\nfrom efficientnet import EfficientNetB0\nfrom keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom keras.layers import GlobalAveragePooling2D, Dense, Dropout\nfrom keras.models import Model\n\ndef bottleneck(x, n_classes):\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(rate=0.25)(x)\n    x = Dense(n_classes, activation='sigmoid')(x)\n    return x\n\ndef get_model(input_shape, n_classes):\n    print(\"input_shape : {}\".format(input_shape))\n    # EfficientNet使う時\n#     effnet_instance = EfficientNetB0(input_shape=input_shape[1:], weights='imagenet', include_top=False)\n#     x = effnet_instance.output()\n\n    # EfficientNet使わない時\n    input_img = Input(input_shape[1:])\n    x = input_img\n    print(\"input\" + str(x))\n    \n    x = bottleneck(x, n_classes)\n    \n    #model = Model(inputs=effnet_instance.input, outputs=x)\n    model = Model(inputs=input_img, outputs=x)\n    \n    return model","execution_count":68,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.compileとmodel.fit : solver.pyに記載\nfrom keras.optimizers import RMSprop\nfrom keras.callbacks import Callback, CSVLogger\n\nclass Solver(object):\n    def __init__(self, dataloder_instance, batch_size, n_epochs):\n        self.data_loader = dataloder_instance\n        self.batch_size = batch_size\n        self.n_epochs = n_epochs\n        self.n_classes = 10\n        print(\"n_classes : {}\".format(self.n_classes))\n        \n        self.model = get_model(input_shape = self.data_loader.x_train.shape, n_classes = self.n_classes)\n        \n        # ファインチューニングする場合は専用のAdamオプティマイザを使う\n        # optimizer = get_adam_for_fine_tuning(lr=1e-3, decay=1e-5, multiplier=0.01, model=model)\n        \n        self.model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),\n                  metrics=['accuracy'])\n    \n    def train(self):\n        # callbackを定義する場合はここに記述\n        self.model.fit(self.data_loader.x_train, self.data_loader.y_train, batch_size=self.batch_size, \\\n                       epochs=self.n_epochs, verbose=1, validation_data=(self.data_loader.x_valid, self.data_loader.y_valid))","execution_count":78,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataloder_ins = Dataloder()\ndataloder_ins.get_data(channel = 1)\n\nsolver_ins = Solver(dataloder_ins, batch_size=10, n_epochs=1)\nsolver_ins.train()","execution_count":80,"outputs":[{"output_type":"stream","text":"n_classes : 10\ninput_shape : (49500, 28, 28, 1)\ninputTensor(\"input_12:0\", shape=(None, 28, 28, 1), dtype=float32)\nTrain on 49500 samples, validate on 10500 samples\nEpoch 1/1\n49500/49500 [==============================] - 16s 328us/step - loss: 2.1522 - accuracy: 0.2029 - val_loss: 2.0750 - val_accuracy: 0.2326\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os, random, cv2\nimport numpy as np\nfrom albumentations import Compose\nfrom albumentations.augmentations.transforms import HorizontalFlip, Normalize\n\nclass DataLoader(object):\n    def __init__(self, data_folder, batch_size, input_shape, do_augmentation, gray_scale=False):\n        self._file_paths = []\n        self._annotations = []\n        folders = os.listdir(data_folder)\n        folders.sort()\n        # 画像のパスとクラスIDを取得する\n        for class_id, class_name in enumerate(folders):\n            folder_path = data_folder + os.sep + class_name\n            file_paths = [folder_path + os.sep + fn for fn in os.listdir(folder_path + os.sep)]\n            self._file_paths += file_paths\n            self._annotations += [class_id]*len(file_paths)\n        # クラス数\n        self._class_count = class_id + 1\n        self._batch_size = batch_size\n        self._input_shape = input_shape\n        self._gray_scale = gray_scale\n        if len(self._file_paths)%self._batch_size == 0:\n            self.iterations = len(self._file_paths) // self._batch_size\n            self._has_extra_data = False\n        else:\n            self.iterations = len(self._file_paths) // self._batch_size + 1\n            self._has_extra_data = True\n        self._compose = self._define_augment(input_shape, do_augmentation)\n\n    def _define_augment(self, input_shape, do_augmentation):\n        # mean, std, max_pixel_valueは適宜変更してください\n        mean = (0.485*255, 0.456*255, 0.406*255)\n        std = (0.229*255, 0.224*255, 0.225*255)\n        normalize = Normalize(mean=mean, std=std, max_pixel_value=1)\n        # データ拡張内容は適宜変更してください\n        if do_augmentation:\n            return Compose([normalize, HorizontalFlip(p=0.5)])\n        else:\n            return Compose([normalize])\n\n    def get_data_loader(self):\n        while True:\n            file_paths, annotations = self._shuffle(self._file_paths, self._annotations)\n            for iteration in range(self.iterations):\n                if iteration == self.iterations - 1 and self._has_extra_data:\n                    shape = (len(file_paths)%self._batch_size, self._input_shape[0],\n                             self._input_shape[1], self._input_shape[2])\n                else:\n                    shape = (self._batch_size, self._input_shape[0], self._input_shape[1], self._input_shape[2])\n                # バッチサイズ分のデータを取得する\n                X = np.zeros(shape, dtype=np.float32)\n                y = np.zeros((shape[0], self._class_count), dtype=np.float32)\n                for i in range(X.shape[0]):\n                    index = self._batch_size*iteration + i\n                    if self._gray_scale:\n                        image = cv2.imread(file_paths[index], cv2.IMREAD_GRAYSCALE)\n                        image = image[:,:,np.newaxis]\n                    else:\n                        image = cv2.imread(file_paths[index])\n                    image = cv2.resize(image, (self._input_shape[1], self._input_shape[0]))\n                    image = image.astype(np.float32)\n                    # データ拡張を実行する\n                    X[i] = self._augment(image)\n                    y[i, annotations[index]] = 1\n                yield X, y\n\n    def _shuffle(self, x, y):\n        p = list(zip(x, y))\n        random.shuffle(p)\n        return zip(*p)\n\n    def _augment(self, image):\n        dict = {'image': image}\n        augmented = self._compose(**dict)\n        return augmented['image']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.legacy import interfaces\nimport keras.backend as K\nfrom keras.optimizers import Optimizer\n\nclass Adam_lr_mult(Optimizer):\n    \"\"\"Adam optimizer.\n    Adam optimizer, with learning rate multipliers built on Keras implementation\n    # Arguments\n        lr: float >= 0. Learning rate.\n        beta_1: float, 0 < beta < 1. Generally close to 1.\n        beta_2: float, 0 < beta < 1. Generally close to 1.\n        epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n        decay: float >= 0. Learning rate decay over each update.\n        amsgrad: boolean. Whether to apply the AMSGrad variant of this\n            algorithm from the paper \"On the Convergence of Adam and\n            Beyond\".\n    # References\n        - [Adam - A Method for Stochastic Optimization](http://arxiv.org/abs/1412.6980v8)\n        - [On the Convergence of Adam and Beyond](https://openreview.net/forum?id=ryQu7f-RZ)\n        \n    AUTHOR: Erik Brorson\n    \"\"\"\n\n    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999,\n                 epsilon=None, decay=0., amsgrad=False,\n                 multipliers=None, debug_verbose=False,**kwargs):\n        super(Adam_lr_mult, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n            self.lr = K.variable(lr, name='lr')\n            self.beta_1 = K.variable(beta_1, name='beta_1')\n            self.beta_2 = K.variable(beta_2, name='beta_2')\n            self.decay = K.variable(decay, name='decay')\n        if epsilon is None:\n            epsilon = K.epsilon()\n        self.epsilon = epsilon\n        self.initial_decay = decay\n        self.amsgrad = amsgrad\n        self.multipliers = multipliers\n        self.debug_verbose = debug_verbose\n\n    @interfaces.legacy_get_updates_support\n    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.lr\n        if self.initial_decay > 0:\n            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n                                                  K.dtype(self.decay))))\n\n        t = K.cast(self.iterations, K.floatx()) + 1\n        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n                     (1. - K.pow(self.beta_1, t)))\n\n        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n        if self.amsgrad:\n            vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n        else:\n            vhats = [K.zeros(1) for _ in params]\n        self.weights = [self.iterations] + ms + vs + vhats\n\n        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n\n            # Learning rate multipliers\n            if self.multipliers:\n                multiplier = [mult for mult in self.multipliers if mult in p.name]\n            else:\n                multiplier = None\n            if multiplier:\n                new_lr_t = lr_t * self.multipliers[multiplier[0]]\n                if self.debug_verbose:\n                    print('Setting {} to learning rate {}'.format(multiplier[0], new_lr_t))\n                    print(K.get_value(new_lr_t))\n            else:\n                new_lr_t = lr_t\n                if self.debug_verbose:\n                    print('No change in learning rate {}'.format(p.name))\n                    print(K.get_value(new_lr_t))\n            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n            if self.amsgrad:\n                vhat_t = K.maximum(vhat, v_t)\n                p_t = p - new_lr_t * m_t / (K.sqrt(vhat_t) + self.epsilon)\n                self.updates.append(K.update(vhat, vhat_t))\n            else:\n                p_t = p - new_lr_t * m_t / (K.sqrt(v_t) + self.epsilon)\n\n            self.updates.append(K.update(m, m_t))\n            self.updates.append(K.update(v, v_t))\n            new_p = p_t\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates\n\n    def get_config(self):\n        config = {'lr': float(K.get_value(self.lr)),\n                  'beta_1': float(K.get_value(self.beta_1)),\n                  'beta_2': float(K.get_value(self.beta_2)),\n                  'decay': float(K.get_value(self.decay)),\n                  'epsilon': self.epsilon,\n                  'amsgrad': self.amsgrad,\n                  'multipliers':self.multipliers}\n        base_config = super(Adam_lr_mult, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_adam_for_fine_tuning(lr, decay, multiplier, model):\n    lr_multiplier = {}\n    # 自分が引っ付けたレイヤーの学習係数は1、学習済みの部分は小さな値を設定する\n    for layer in model.layers:\n        if 'dense' in layer.name:\n            lr_multiplier[layer.name] = 1.0\n        else:\n            lr_multiplier[layer.name] = multiplier\n    return Adam_lr_mult(lr=lr, decay=decay, multipliers=lr_multiplier)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ClsTestDataset(Dataset):\n\n    def __init__(self, num_samples=1, model='densenet161'):\n        \n        self.num_samples = num_samples\n        self.images = np.zeros([num_samples, WIDTH * HEIGHT], dtype=np.uint8)\n    \n        self.aug = albumentations.Compose([\n            albumentations.Resize(int(HEIGHT), int(WIDTH), always_apply=True),\n            albumentations.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225], always_apply=True)\n        ])\n    \n        img_id = 0\n\n        for i in tqdm(range(4)):\n            datafile = INPUT_PATH + '/test_image_data_{}.parquet'.format(i)\n            parq = pq.read_pandas(datafile, columns=[str(x) for x in range(32332)]).to_pandas()\n            parq =  parq.iloc[:, :].values.reshape(-1, HEIGHT, WIDTH).astype(np.uint8)\n            \n            for idx, image in enumerate(parq):\n                self.images[img_id, ...] = image.reshape(-1).astype(np.uint8)\n                img_id = img_id + 1\n                \n        del parq\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        \n        img = self.images[idx]\n        img = img.reshape(HEIGHT, WIDTH).astype(float)\n        img = Image.fromarray(img).convert(\"RGB\")\n        img = self.aug(image=np.array(img))[\"image\"]\n        img = np.transpose(img, (2, 0, 1)).astype(np.float32)\n        img = torch.tensor(img, dtype=torch.float)\n\n        return {\n            \"image\": img,\n            \"image_id\": idx\n        }","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}